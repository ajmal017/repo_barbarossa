
(PAGE 2) There's mention of some potentially useful papers in literature review 2.1-2.4.

(PAGE 4) Cointegration amounts to running a levels regression checking the residuals for stationarity.

(PAGE 4) Rolling OLS is the least favoured in the literature due to the ghost effect, lagging effect and 
drop-out effect.

(PAGE 5) The average OLS rolling window length found using the genetic algorithm was 200 data points.

(PAGE 5) Double Exponential Smoothing Prediction model is an interesting way of constantly adjusting the
coefficient between the two assets.

(PAGE 5) Kalman filter is another way of constantly adjusting the coefficient.

(PAGE 6) No constant in these models hence fewer parameters to estimate.

(PAGE 7) They calculate half life of mean reversion as a way to predict the success of a certain pair.

(PAGE 8) Assumed transaction cost is %0.15 for each transaction.

(PAGE 8) Kalman filter seems to provide the superior information ratio for all the frequencies.

(PAGE 10) Information ratio in higher frequencies, seems to be effected quite a bit from a conservative
transaction cost assumption.

(PAGE 11) Looking at the results of in sample cointegration test doesn't seem to provide much 
predictability for out of sample information ratio. 

(PAGE 12) They found that cointegration stats for a pair don't vary that much accross different frequencies.

(PAGE 13) In sample information ratio and half life indicators seem to have some preductive power 
for out of sample information ratio.

(PAGE 13) They discard half life as the results are not that attractive.

(PAGE 15) Information ratio net of trading costs for daily data can be improved from 0.7 to 1.3
using the in-sample information ratio as an indicator of the future profitability of pairs. Similar
filtering idea works for high-frequency intervals.

(PAGE 17) Kalman filter estimation details.



